{"idx": 0, "solver": "urdufactcheck_claimprocessor", "continue": true, "state": {"question": null, "response": "جی پی ٹی تھری کے سب سے بڑے ماڈل کا حجم کیا ہے؟ جی پی ٹی تھری کا سب سے بڑا ماڈل 175 ارب پیرا میٹرز پر مشتمل ہے۔", "claims": ["جی پی ٹی تھری کا سب سے بڑا ماڈل 175 ارب پیرا میٹرز پر مشتمل ہے"]}}
{"idx": 1, "solver": "urdufactcheck_translator_retriever", "continue": true, "state": {"question": null, "response": "جی پی ٹی تھری کے سب سے بڑے ماڈل کا حجم کیا ہے؟ جی پی ٹی تھری کا سب سے بڑا ماڈل 175 ارب پیرا میٹرز پر مشتمل ہے۔", "claims": ["جی پی ٹی تھری کا سب سے بڑا ماڈل 175 ارب پیرا میٹرز پر مشتمل ہے"], "claims_with_evidences": {"جی پی ٹی تھری کا سب سے بڑا ماڈل 175 ارب پیرا میٹرز پر مشتمل ہے": [["جی پی ٹی تھری کے ماڈل میں کتنے پیرا میٹرز ہیں؟ جی پی ٹی تھری کا سب سے بڑا ماڈل", "جی پی ٹی-3 کا ڈیپ لرننگ نیورل نیٹ ورک ایک ماڈل ہے جس میں 17 ارب سے زیادہ مشین لرننگ کے پیرامیٹرز ہیں۔ چیزوں کو سمجھنے کے لیے، جی پی ٹی-3 سے پہلے کا سب سے بڑا تربیت یافتہ زبان ماڈل مائیکروسافٹ کا ٹورنگ نیچرل لینگویج جنریشن (NLG) ماڈل تھا، جس میں 17 ارب پیرامیٹرز تھے۔"], ["جی پی ٹی تھری کے ماڈل میں کتنے پیرا میٹرز ہیں؟ جی پی ٹی تھری کا سب سے بڑا ماڈل", "سب سے بڑی ورژن GPT-3 175B یا \"GPT-3\" میں 175 بلین پیرا میٹرز، 96 توجہ کی تہیں اور 3.2 ملین بیچ سائز ہے۔ اوپر دی گئی شکل میں اصل ٹرانسفارمر آرکیٹیکچر دکھایا گیا ہے۔ جیسا کہ پہلے ذکر کیا گیا، اوپن اے آئی GPT-3 اسی طرح کی آرکیٹیکچر پر مبنی ہے، صرف یہ کہ یہ کافی بڑا ہے۔"]]}}}
{"idx": 2, "solver": "urdufactcheck_verifier", "continue": true, "state": {"question": null, "response": "جی پی ٹی تھری کے سب سے بڑے ماڈل کا حجم کیا ہے؟ جی پی ٹی تھری کا سب سے بڑا ماڈل 175 ارب پیرا میٹرز پر مشتمل ہے۔", "claims": ["جی پی ٹی تھری کا سب سے بڑا ماڈل 175 ارب پیرا میٹرز پر مشتمل ہے"], "claims_with_evidences": {"جی پی ٹی تھری کا سب سے بڑا ماڈل 175 ارب پیرا میٹرز پر مشتمل ہے": [["جی پی ٹی تھری کے ماڈل میں کتنے پیرا میٹرز ہیں؟ جی پی ٹی تھری کا سب سے بڑا ماڈل", "جی پی ٹی-3 کا ڈیپ لرننگ نیورل نیٹ ورک ایک ماڈل ہے جس میں 17 ارب سے زیادہ مشین لرننگ کے پیرامیٹرز ہیں۔ چیزوں کو سمجھنے کے لیے، جی پی ٹی-3 سے پہلے کا سب سے بڑا تربیت یافتہ زبان ماڈل مائیکروسافٹ کا ٹورنگ نیچرل لینگویج جنریشن (NLG) ماڈل تھا، جس میں 17 ارب پیرامیٹرز تھے۔"], ["جی پی ٹی تھری کے ماڈل میں کتنے پیرا میٹرز ہیں؟ جی پی ٹی تھری کا سب سے بڑا ماڈل", "سب سے بڑی ورژن GPT-3 175B یا \"GPT-3\" میں 175 بلین پیرا میٹرز، 96 توجہ کی تہیں اور 3.2 ملین بیچ سائز ہے۔ اوپر دی گئی شکل میں اصل ٹرانسفارمر آرکیٹیکچر دکھایا گیا ہے۔ جیسا کہ پہلے ذکر کیا گیا، اوپن اے آئی GPT-3 اسی طرح کی آرکیٹیکچر پر مبنی ہے، صرف یہ کہ یہ کافی بڑا ہے۔"]]}, "detail": [{"reasoning": "دی گئی عبارت میں جی پی ٹی تھری کے ماڈل کی تعداد 175 ارب پیرا میٹرز بتائی گئی ہے، جو کہ درست ہے۔ فراہم کردہ شواہد میں بھی یہ بات واضح کی گئی ہے کہ جی پی ٹی-3 میں 175 بلین پیرا میٹرز ہیں۔", "error": "None", "correction": "None", "factuality": true, "claim": "جی پی ٹی تھری کا سب سے بڑا ماڈل 175 ارب پیرا میٹرز پر مشتمل ہے", "evidences": [["جی پی ٹی تھری کے ماڈل میں کتنے پیرا میٹرز ہیں؟ جی پی ٹی تھری کا سب سے بڑا ماڈل", "جی پی ٹی-3 کا ڈیپ لرننگ نیورل نیٹ ورک ایک ماڈل ہے جس میں 17 ارب سے زیادہ مشین لرننگ کے پیرامیٹرز ہیں۔ چیزوں کو سمجھنے کے لیے، جی پی ٹی-3 سے پہلے کا سب سے بڑا تربیت یافتہ زبان ماڈل مائیکروسافٹ کا ٹورنگ نیچرل لینگویج جنریشن (NLG) ماڈل تھا، جس میں 17 ارب پیرامیٹرز تھے۔"], ["جی پی ٹی تھری کے ماڈل میں کتنے پیرا میٹرز ہیں؟ جی پی ٹی تھری کا سب سے بڑا ماڈل", "سب سے بڑی ورژن GPT-3 175B یا \"GPT-3\" میں 175 بلین پیرا میٹرز، 96 توجہ کی تہیں اور 3.2 ملین بیچ سائز ہے۔ اوپر دی گئی شکل میں اصل ٹرانسفارمر آرکیٹیکچر دکھایا گیا ہے۔ جیسا کہ پہلے ذکر کیا گیا، اوپن اے آئی GPT-3 اسی طرح کی آرکیٹیکچر پر مبنی ہے، صرف یہ کہ یہ کافی بڑا ہے۔"]]}], "label": true}}
